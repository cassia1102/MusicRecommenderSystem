{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e138bcc1",
   "metadata": {},
   "source": [
    "###                                                HW9\n",
    "1. Download the new test2_new.txt data which contains the ground-truth of the track ID recommendations. \n",
    "\n",
    "2. Use the userID in test2_new.txt to fetch the related rating scores in the training data for the same users. \n",
    "\n",
    "3. For the fetched rating score matrix, use the \"1\" and \"0\" recommendations in test2 to training your classifier.  You need to use \n",
    "\n",
    "from pyspark.ml.classification import ******\n",
    "You need to try 4 different classifiers in the pyspark.ml library as shown in the lecture notes to train your models.  \n",
    "\n",
    "4. Then apply the trained models to what you fetched rating scores from the final project test data and make predictions.  Submit your new results at Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5216a",
   "metadata": {},
   "source": [
    "#### 1.build the Gradient-Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e88f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c cyclus java-jdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c06f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21861970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/30 16:15:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/04/30 16:15:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/04/30 16:15:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/04/30 16:15:56 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/04/30 16:15:56 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "#load pySpark modules \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c64dc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|      TrackID|rating|\n",
      "+-------------+------+\n",
      "| 200031_30877|     1|\n",
      "|  200031_8244|     1|\n",
      "|200031_130183|     0|\n",
      "|200031_198762|     0|\n",
      "| 200031_34503|     1|\n",
      "+-------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load training data file into pySpark dataFrame format\n",
    "\n",
    "training = spark.read.csv(\"test_new.csv\", header = False)\n",
    "#rename training dataFrame column names\n",
    "\n",
    "training = training.withColumnRenamed(\"_c0\", \"userID\").withColumnRenamed(\"_c1\", \"itemID\").withColumnRenamed(\"_c2\", \"rating\")\n",
    "training = training.withColumn('TrackID', F.concat(F.col('userID'),F.lit('_'), F.col('itemID'))).select('TrackID','rating')\n",
    "training.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425e594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|userID|itemID|score1|score2|\n",
      "+------+------+------+------+\n",
      "|199810|208019|   0.0|   0.0|\n",
      "|199810| 74139|   0.0|   0.0|\n",
      "|199810|  9903|   0.0|   0.0|\n",
      "|199810|242681|   0.0|   0.0|\n",
      "|199810| 18515|   0.0|  70.0|\n",
      "+------+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = spark.read.csv(\"score.csv\", header = False)\n",
    "#rename training dataFrame column names\n",
    "\n",
    "score = score.withColumnRenamed(\"_c0\", \"userID\").withColumnRenamed(\"_c1\", \"itemID\").withColumnRenamed(\"_c2\", \"score1\").withColumnRenamed(\"_c3\", \"score2\")\n",
    "\n",
    "score.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d1bd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|      TrackID|weighted_score|\n",
      "+-------------+--------------+\n",
      "|199810_208019|           0.0|\n",
      "| 199810_74139|           0.0|\n",
      "|  199810_9903|           0.0|\n",
      "|199810_242681|           0.0|\n",
      "| 199810_18515|          14.0|\n",
      "+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weighted_score = score.withColumn(\"weighted_score\", F.round(0.8*score.score1+0.2*score.score2))\n",
    "weighted_score = weighted_score.withColumn('TrackID', F.concat(F.col('userID'),F.lit('_'), F.col('itemID'))).select('TrackID','weighted_score')\n",
    "weighted_score.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2172ed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TrackID: string (nullable = true)\n",
      " |-- weighted_score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weighted_score.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565df6d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------+\n",
      "|      TrackID|weighted_score|rating|\n",
      "+-------------+--------------+------+\n",
      "| 200031_30877|          82.0|     1|\n",
      "|  200031_8244|          72.0|     1|\n",
      "|200031_130183|           0.0|     0|\n",
      "|200031_198762|           0.0|     0|\n",
      "| 200031_34503|          82.0|     1|\n",
      "|200031_227283|          18.0|     0|\n",
      "+-------------+--------------+------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = training.join(weighted_score,training.TrackID == weighted_score.TrackID,\"inner\").drop(weighted_score.TrackID).select('TrackID','weighted_score','rating')\n",
    "df.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f0bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TrackID: string (nullable = true)\n",
      " |-- weighted_score: double (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434af46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------+\n",
      "|      TrackID|weighted_score|rating|\n",
      "+-------------+--------------+------+\n",
      "| 200031_30877|          82.0|     1|\n",
      "|  200031_8244|          72.0|     1|\n",
      "|200031_130183|           0.0|     0|\n",
      "+-------------+--------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df = df.withColumn(\"weighted_score\", df[\"weighted_score\"].cast('float'))\n",
    "\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a130f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TrackID: string (nullable = true)\n",
      " |-- weighted_score: float (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a0880",
   "metadata": {},
   "source": [
    "### build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4047a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer,VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "600b3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure an ML pipeline\n",
    "label_stringIdx = StringIndexer(inputCol = 'rating', outputCol = 'label')\n",
    "numericCols = ['weighted_score']\n",
    "numVect = VectorAssembler(inputCols = ['weighted_score'], outputCol=\"features\")\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "pipeline = Pipeline(stages=[numVect, label_stringIdx, gbt])\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "# Fit the pipeline to training documents.\n",
    "gbtmodel = pipeline.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed1546",
   "metadata": {},
   "source": [
    "### Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab1912e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------+--------+-----+--------------------+--------------------+----------+\n",
      "|      TrackID|weighted_score|rating|features|label|       rawPrediction|         probability|prediction|\n",
      "+-------------+--------------+------+--------+-----+--------------------+--------------------+----------+\n",
      "|200031_130183|           0.0|     0|   [0.0]|  0.0|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "| 200032_18681|          90.0|     1|  [90.0]|  1.0|[-1.2967852195058...|[0.06955336402159...|       1.0|\n",
      "| 200032_64167|          90.0|     1|  [90.0]|  1.0|[-1.2967852195058...|[0.06955336402159...|       1.0|\n",
      "|200055_134398|          18.0|     1|  [18.0]|  1.0|[-0.6430944326812...|[0.21649858344049...|       1.0|\n",
      "| 200055_56695|          90.0|     1|  [90.0]|  1.0|[-1.2967852195058...|[0.06955336402159...|       1.0|\n",
      "|200065_179571|           0.0|     0|   [0.0]|  0.0|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "| 200065_26875|          90.0|     1|  [90.0]|  1.0|[-1.2967852195058...|[0.06955336402159...|       1.0|\n",
      "|200074_142078|           0.0|     0|   [0.0]|  0.0|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "|200074_269977|           0.0|     0|   [0.0]|  0.0|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "|200074_276467|          18.0|     1|  [18.0]|  1.0|[-0.6430944326812...|[0.21649858344049...|       1.0|\n",
      "| 200074_38502|          90.0|     1|  [90.0]|  1.0|[-1.2967852195058...|[0.06955336402159...|       1.0|\n",
      "|200085_284406|           0.0|     0|   [0.0]|  0.0|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "+-------------+--------------+------+--------+-----+--------------------+--------------------+----------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = gbtmodel.transform(test)\n",
    "predictions.show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea981cf",
   "metadata": {},
   "source": [
    "### Evaluate our Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4946926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|             680.0|\n",
      "|       FP|              67.0|\n",
      "|       TN|             770.0|\n",
      "|       FN|             197.0|\n",
      "|Precision|0.9103078982597055|\n",
      "|   Recall|0.7753705815279361|\n",
      "|       F1|0.8374384236453202|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluating prediction results\n",
    "\n",
    "tp = float(predictions.filter(\"prediction == 1.0 AND rating == 1\").count())\n",
    "fp = float(predictions.filter(\"prediction == 1.0 AND rating == 0\").count())\n",
    "tn = float(predictions.filter(\"prediction == 0.0 AND rating == 0\").count())\n",
    "fn = float(predictions.filter(\"prediction == 0.0 AND rating == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", pr),\n",
    " (\"Recall\", re),\n",
    " (\"F1\", 2*pr*re/(re+pr))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be658174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.8688718328068018\n"
     ]
    }
   ],
   "source": [
    "#Evaluate our Logistic Regression model.\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b16c4bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.131128\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac5064",
   "metadata": {},
   "source": [
    "### Make predictions on the rating scores data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76bfa1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+--------+--------------------+--------------------+----------+\n",
      "|      TrackID|weighted_score|features|       rawPrediction|         probability|prediction|\n",
      "+-------------+--------------+--------+--------------------+--------------------+----------+\n",
      "|199810_208019|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "| 199810_74139|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "|  199810_9903|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "|199810_242681|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "| 199810_18515|          14.0|  [14.0]|[-0.2645640406367...|[0.37072027218164...|       1.0|\n",
      "|199810_105760|          18.0|  [18.0]|[-0.6430944326812...|[0.21649858344049...|       1.0|\n",
      "|199812_276940|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "|199812_142408|         100.0| [100.0]|[-1.3259026792203...|[0.06587782434721...|       1.0|\n",
      "|199812_130023|         100.0| [100.0]|[-1.3259026792203...|[0.06587782434721...|       1.0|\n",
      "| 199812_29189|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "|199812_223706|          20.0|  [20.0]|[-0.9484834135042...|[0.13045215499582...|       1.0|\n",
      "|199812_211361|           0.0|   [0.0]|[0.70770409311086...|[0.80461755545132...|       0.0|\n",
      "+-------------+--------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/30 16:28:05 WARN StringIndexerModel: Input column rating does not exist during transformation. Skip StringIndexerModel for this column.\n"
     ]
    }
   ],
   "source": [
    "#Use the model to pedict the whole test data\n",
    "prediction_all = gbtmodel.transform(weighted_score)\n",
    "prediction_all.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6eb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"TrackID\",\"Predictor\"\n",
    "prediction_All = prediction_all.withColumnRenamed(\"prediction\", \"Predictor\").select(\"TrackID\",\"Predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18c643b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      TrackID|Predictor|\n",
      "+-------------+---------+\n",
      "|199810_208019|      0.0|\n",
      "| 199810_74139|      0.0|\n",
      "|  199810_9903|      0.0|\n",
      "|199810_242681|      0.0|\n",
      "| 199810_18515|      1.0|\n",
      "+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_All.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c113050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_All.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9b0c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#save the results to csv file\n",
    "prediction_All.toPandas().to_csv('prediction_gbt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99366c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
